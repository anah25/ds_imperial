{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2549520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pathlib as pl\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8c6a33",
   "metadata": {},
   "source": [
    "# Metrics for Model Selection\n",
    "\n",
    "In this notebook you will fit polynomials to data to decide which order of polynomial is the best fit. Unlike before, the data you will be using is 3 dimensional, meaning it isn't possible to plot. Instead, you will write functions to calculate various metrics that are used to determine model fit. \n",
    "\n",
    "Complete this notebook, then answer the questions that go along side it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b83af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "seed = 2022\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f323453",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b160e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = pl.Path(os.getcwd()) / f'M6_Performance_Metrics_Data.csv'\n",
    "with open(path_csv, 'rb') as file:\n",
    "    data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2565b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        x1        x2        x3          y\n",
      "0           0  0.382303 -1.596593  1.233776   4.935364\n",
      "1           1  1.902436  1.579109 -0.341741  25.138660\n",
      "2           2 -1.689244  1.298489 -1.472081  -4.786340\n",
      "3           3 -1.510509  1.937616 -1.600244  -3.185759\n",
      "4           4  1.621717  0.515558 -1.869644  19.712731\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2d5f09",
   "metadata": {},
   "source": [
    "## Section 1 : Split the data into training, validation and test sets\n",
    "\n",
    "### TO DO: write a function that splits the data into traning, validation and test sets.\n",
    "\n",
    "The function should take as inputs the dataframe and the percentage splits for each of training, validation and test. It should output 3 dataframes, one for each of the sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cfe21f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.382303</td>\n",
       "      <td>-1.596593</td>\n",
       "      <td>1.233776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.902436</td>\n",
       "      <td>1.579109</td>\n",
       "      <td>-0.341741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.689244</td>\n",
       "      <td>1.298489</td>\n",
       "      <td>-1.472081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.510509</td>\n",
       "      <td>1.937616</td>\n",
       "      <td>-1.600244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.621717</td>\n",
       "      <td>0.515558</td>\n",
       "      <td>-1.869644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.369062</td>\n",
       "      <td>1.344716</td>\n",
       "      <td>-0.545936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.236030</td>\n",
       "      <td>1.027829</td>\n",
       "      <td>0.105539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.415708</td>\n",
       "      <td>-0.626697</td>\n",
       "      <td>1.076959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.467675</td>\n",
       "      <td>1.527521</td>\n",
       "      <td>0.675122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.126524</td>\n",
       "      <td>1.807901</td>\n",
       "      <td>-0.740513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2        x3\n",
       "0   0.382303 -1.596593  1.233776\n",
       "1   1.902436  1.579109 -0.341741\n",
       "2  -1.689244  1.298489 -1.472081\n",
       "3  -1.510509  1.937616 -1.600244\n",
       "4   1.621717  0.515558 -1.869644\n",
       "..       ...       ...       ...\n",
       "95 -0.369062  1.344716 -0.545936\n",
       "96 -1.236030  1.027829  0.105539\n",
       "97 -0.415708 -0.626697  1.076959\n",
       "98 -0.467675  1.527521  0.675122\n",
       "99 -0.126524  1.807901 -0.740513\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8b80816",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your function here ##\n",
    "\n",
    "def split_data(df, ratios_list):\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    train_ratio = ratios_list[0]\n",
    "    validation_ratio = ratios_list[1]\n",
    "    test_ratio = ratios_list[2]\n",
    "    \n",
    "    # train is now 75% of the entire data set\n",
    "    # # the _junk suffix means that we drop that variable completely\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data.iloc[:,1:-1], data.iloc[:,-1], test_size=1 - train_ratio)\n",
    "\n",
    "    # test is now 10% of the initial data set\n",
    "    # validation is now 15% of the initial data set\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "    \n",
    "    return x_train, x_val, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4f0de2",
   "metadata": {},
   "source": [
    "### TO DO: Use your function to split the data so the training set has 40% of the data and the validation and test sets have 30% of the data each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e70a19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          x1        x2        x3\n",
       " 23 -0.496090  1.552690 -1.333864\n",
       " 99 -0.126524  1.807901 -0.740513\n",
       " 54  0.583874 -1.257991 -1.220823\n",
       " 16 -1.144002  0.949800  0.866272\n",
       " 65  0.308612 -0.923909 -0.235798\n",
       " 40 -1.057484 -0.005690 -0.318702\n",
       " 94  0.632650 -1.628347  1.683086\n",
       " 80 -1.359348 -1.780858  0.847985\n",
       " 28 -1.044932 -1.981752  1.856430\n",
       " 60  0.948066  1.626476 -0.151725\n",
       " 0   0.382303 -1.596593  1.233776\n",
       " 57  0.403963 -1.396032  0.560340\n",
       " 62 -1.670056  0.362760  1.394161\n",
       " 25  1.051658  1.366586 -0.973434\n",
       " 56  1.127148  0.655574  0.900366\n",
       " 14  1.889985  0.464764 -1.297304\n",
       " 55 -1.277623 -0.817546 -1.888549\n",
       " 95 -0.369062  1.344716 -0.545936\n",
       " 75  0.627830 -1.468808 -1.339753\n",
       " 20  1.148637 -0.128755 -0.384135\n",
       " 6  -0.581466 -1.672979 -0.331812\n",
       " 30 -0.251202  1.921266  0.645585\n",
       " 24  1.808328 -0.137865 -0.016387\n",
       " 36  0.723287 -0.578830 -0.655962\n",
       " 4   1.621717  0.515558 -1.869644\n",
       " 82  1.157484 -0.758447  1.424520\n",
       " 89 -1.083336  0.410126 -1.567022\n",
       " 79 -1.386593  1.158374  1.994851\n",
       " 71 -0.162152  1.373440  0.411232\n",
       " 61  1.190430 -0.458804  0.809956\n",
       " 53 -1.865304 -0.964960 -1.988133\n",
       " 46 -0.374509  0.734371 -1.992420\n",
       " 26 -0.876544 -1.219281 -0.748145\n",
       " 42 -0.669088 -1.536327 -0.522579\n",
       " 48  1.252673 -1.396606 -1.472395\n",
       " 18 -0.430916  1.401128 -0.480641\n",
       " 33  1.842447 -0.730029 -1.208410\n",
       " 3  -1.510509  1.937616 -1.600244\n",
       " 37 -1.066721 -0.806202 -1.603302\n",
       " 88 -1.890215 -0.276761 -1.039610,\n",
       "           x1        x2        x3\n",
       " 58 -1.268421 -1.431103  0.282959\n",
       " 12 -1.096106  0.560155 -0.072257\n",
       " 15 -0.585360 -0.023728  1.032742\n",
       " 11 -1.791881  1.247531 -1.404802\n",
       " 87 -0.206884  0.556944 -0.991252\n",
       " 43 -1.091948 -0.585556  0.894491\n",
       " 44  0.577581  0.561392  0.003785\n",
       " 35  0.497772  0.803435 -0.801939\n",
       " 50  0.457478 -1.022804  0.046429\n",
       " 59 -1.942558 -1.115170  1.361757\n",
       " 78 -1.987114  0.326288 -0.327055\n",
       " 7   1.409334 -1.663275 -0.899389\n",
       " 52  1.262583  0.234466 -0.132652\n",
       " 17 -0.880164  0.077271 -1.176139\n",
       " 85  0.406381 -0.546997  1.114878\n",
       " 68  1.378123  1.912483  0.119204\n",
       " 22 -0.359099  0.952081  1.743385\n",
       " 98 -0.467675  1.527521  0.675122\n",
       " 10  1.009490 -0.526579 -1.682165\n",
       " 90  1.210553 -1.960263  1.896941\n",
       " 38 -1.540892 -1.914233  0.094931\n",
       " 45 -0.355683 -0.487864  1.451096\n",
       " 83 -1.893098  0.440954 -0.797749\n",
       " 64  0.897903  1.426707  0.797498\n",
       " 1   1.902436  1.579109 -0.341741\n",
       " 9  -0.473046 -0.477313 -0.483007\n",
       " 19  1.069111 -1.184526  0.576039\n",
       " 5  -1.928868 -1.475115 -0.677217\n",
       " 41  1.026876  0.085351 -0.194542\n",
       " 70 -0.202824  1.552231  0.057511,\n",
       "           x1        x2        x3\n",
       " 29 -1.562076 -0.827114 -1.350314\n",
       " 76  1.790229  0.389979  1.157690\n",
       " 74 -0.409170 -1.331770  0.803696\n",
       " 97 -0.415708 -0.626697  1.076959\n",
       " 73  1.090002  1.293430  1.852566\n",
       " 86 -0.701848  0.202234 -1.035928\n",
       " 51 -1.598495 -0.562274 -0.477370\n",
       " 92 -0.170697  1.568891 -1.732563\n",
       " 32  0.865403  0.688480 -0.879786\n",
       " 81 -1.860359  1.456796 -0.716871\n",
       " 77 -1.207163  1.244802  1.636311\n",
       " 67  1.384385 -0.544277  1.379405\n",
       " 96 -1.236030  1.027829  0.105539\n",
       " 93  1.636172  0.576516 -1.850643\n",
       " 13  1.629689  1.228442 -1.951963\n",
       " 21 -0.281362 -1.523042 -0.685317\n",
       " 72  0.205552 -0.087599  0.738497\n",
       " 34 -1.947620  0.509861  0.771109\n",
       " 31  0.445146 -0.360236  0.929659\n",
       " 84 -0.161022  0.033720  0.130973\n",
       " 63  1.234521  0.049401  1.836281\n",
       " 8  -1.068701 -0.764019  0.805561\n",
       " 39  1.552398 -1.767069 -0.447956\n",
       " 91  1.680248 -1.899313  0.861771\n",
       " 66  0.032865  0.273388  1.605923\n",
       " 2  -1.689244  1.298489 -1.472081\n",
       " 49  1.800842  0.017108 -0.129432\n",
       " 69 -1.591721  1.030819  1.479829\n",
       " 27 -0.699577  0.431419 -0.420143\n",
       " 47 -1.892543  0.086870  1.675673)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### write your code here ####\n",
    "\n",
    "x_train, x_val, x_test = split_data(data, [0.4,0.3, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135eeba7",
   "metadata": {},
   "source": [
    "## Section 2: Write Metrics Functions \n",
    "\n",
    "### TO DO: Write the functions that calcluate the metrics you will use to evaluate the model fits\n",
    "\n",
    "Write Functions that return:\n",
    "- The mean absolute error\n",
    "- The average error\n",
    "- The mean absolute percentage error \n",
    "- The root mean squared error \n",
    "- The total sum of squared errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1df5874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here ##\n",
    "\n",
    "def mae(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(np.abs(y_true - predictions))\n",
    "\n",
    "def ae(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(y_true - predictions)\n",
    "\n",
    "def mape(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(np.abs((y_true - predictions)/predictions))\n",
    "\n",
    "def rmse(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(np.sqrt(y_true - predictions)^2)\n",
    "\n",
    "def sse(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.sum((y_true - predictions)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4f258",
   "metadata": {},
   "source": [
    "## Section 3: Fit models to training data and calculate performance metric on validation sets\n",
    "\n",
    "For polynomials of order 1, 2, 3, and 4, you will use fit_model to fit each each model. This function uses scikit-learn polynomial regression. \n",
    "\n",
    "\n",
    "### TODO: write function to convert dataframe into numpy arrays\n",
    "\n",
    "The scikit-learn functions take numpy arrays as their inputs. Therefore before you can fit any data you need to write a function to turn a dataframe with columns [x1, x2, x3, y] into two numpy arrays: X and y. X should have dimensions (N, D), where N is the number of data points and D is the dimensionality of the data (in this case 3). y should have dimensions (N, ). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "206866ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X, y, order):\n",
    "    \"\"\"creates scikit-learn regression object and fits it to the X and y data\"\"\"\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=order)),\n",
    "                      ('linear', LinearRegression(fit_intercept=False))])\n",
    "    model = model.fit(X, y)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42198274",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write your function here ## \n",
    "\n",
    "def to_numpy_df(df):\n",
    "    X = df.iloc[:,1:-1].to_numpy()\n",
    "    y = df.iloc[:,:-1].to_numpy()\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005500f",
   "metadata": {},
   "source": [
    "### TO DO: For polynomials of order 1 to 6 inclusive: \n",
    "1. Fit a polynomial to the training data using the fit_model function \n",
    "2. Use model.predict(X) to get the model predictions on the validation set\n",
    "3. Store the model in a dictionary of models where the keys indicate the order and the items are the models\n",
    "4. Store the predictions in a seperate dictionary where the keys indicate the order and the items are numpy arrays of the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34b4f860",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (100,3) into shape (100,0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6496/3530135270.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Fit polynomials of orders 0 to 30 and store them in the array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtraining_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6496/2730317661.py\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(X, y, order)\u001b[0m\n\u001b[0;32m      3\u001b[0m     model = Pipeline([('poly', PolynomialFeatures(degree=order)),\n\u001b[0;32m      4\u001b[0m                       ('linear', LinearRegression(fit_intercept=False))])\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dobre\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32mc:\\Users\\dobre\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dobre\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dobre\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dobre\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dobre\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                 \u001b[1;31m# d = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m                 \u001b[0mXP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcurrent_col\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m                 index = list(range(current_col,\n\u001b[0;32m   1812\u001b[0m                                    current_col + n_features))\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (100,3) into shape (100,0)"
     ]
    }
   ],
   "source": [
    "#Create an empty array to store the fitted polynomial functions\n",
    "p = {}\n",
    "\n",
    "#Fit polynomials of orders 0 to 30 and store them in the array\n",
    "for i in range(0,7):\n",
    "    model = fit_model(X, y, i)\n",
    "    model.predict(X)\n",
    "    training_dict = {i: model}\n",
    "    # predictions_dict = model.predict()\n",
    "\n",
    "# display(model_1)\n",
    "# model_1.predict(X)\n",
    "\n",
    "# for i in range(1,7):\n",
    "#     X, y = to_numpy_df(data)\n",
    "#     fit_model(X, y, i)\n",
    "training_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc41eccd",
   "metadata": {},
   "source": [
    "## Section 4: Calculate metrics for each of the models\n",
    "\n",
    "Now we want to calculate the metrics for each of the models. \n",
    "\n",
    "\n",
    "### TODO: Use the dictionary of predictions you have to caluclate and record (could be in a dataframe, or you could plot it on a graph) each of the metrics. \n",
    "1. Calculate each of the metrics for the model using the functions you wrote before\n",
    "2. Store the metrics in a dataframe, with one row for each model or plot on a graph\n",
    "3. Answer the questions that go alongside this notebook \n",
    "\n",
    "HINT: you can write a list of functions of the form:\n",
    "\n",
    "methods = [RMSE, average_error, mean_abs_percent_error, total_sum_squared_error]\n",
    "\n",
    "which you can then iterate over using a for loop. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e87a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2caeaa",
   "metadata": {},
   "source": [
    "## Section 5: Use the test set to evaluate the performance of your chosen model\n",
    "\n",
    "### TODO: For your selected model, calculate the RMSE, Average Error and Mean Absolute Percentage Error of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166cc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write your code here ## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3ad02e8f3ef77bf09cfe88d8a9da3fa8c5ec4ee3868648142e9052f0e179fbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
